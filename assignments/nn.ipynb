{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "#### Part I: Multi-layer Perceptron\n",
    "\n",
    "***\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [material/nns_pytorch.ipynb](material/nns_pytorch.ipynb)\n",
    "\n",
    "Table of contents:\n",
    "1. Activate GPU\n",
    "2. Load data\n",
    "3. Inspect data\n",
    "4. Artificial neural network (**Where you will implement the ANN**)\n",
    "5. Training hyperparameters (**Where you will add training parameters**)\n",
    "6. Training\n",
    "7. Plot loss and accuracy\n",
    "8. Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxilary imports\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a bit of a hack in case your IDE wants to run the notebook from /`assignment/` and not the project root folder `/ma1`. We need the working directory to be `/ma1` for local imports to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the working directory is set to the \"ma1\" folder.\n",
    "while Path.cwd().name != \"ma1\" and \"ma1\" in str(Path.cwd()):\n",
    "    os.chdir(\"..\")  # Move up one directory\n",
    "print(f\"Working directory set to: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import local files\n",
    "\n",
    "To declutter the notebooks, your are given a module (`/src`) of useful functions. Please study each one as they contain important code (particularly `src.training` and `src.evaluation`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local files\n",
    "from src.utils import get_device\n",
    "from src.data import load_torch_data, to_dataloader, train_val_split\n",
    "from src.training import fit\n",
    "from src.evaluation import evaluate\n",
    "from src.visualize import plot_training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Activate GPU\n",
    "If available. Note that this is not necessary, but it will speed up your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training/validation data\n",
    "train_val = load_torch_data(\n",
    "    dataset=\"MNIST\",\n",
    "    root = 'data',                     # The root directory where the dataset will be stored\n",
    "    download = True,                   # If the dataset is not found at root, it will be downloaded\n",
    "    train = True,                      # The train dataset (as opposed to the test dataset)\n",
    "    transform = transforms.ToTensor()  # transformations to be applied to the dataset (only cast to tensor)\n",
    ")\n",
    "\n",
    "# load the testing data\n",
    "test = load_torch_data(\n",
    "    dataset = \"MNIST\",\n",
    "    root = 'data',\n",
    "    download = True,\n",
    "    train = False,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "f\"{len(train_val)=}, {len(test)=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data in training and validation (just like train_test_split in sklearn)\n",
    "train, val = train_val_split(train_val, val_ratio=0.2, seed=42)\n",
    "\n",
    "f\"{len(val)=}, {len(train)=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloders for easy batch loading during training\n",
    "train_loader = to_dataloader(train, batch_size = 64, shuffle = True)\n",
    "val_loader = to_dataloader(val, batch_size = 64, shuffle = False)\n",
    "test_loader = to_dataloader(test, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random example from the training set\n",
    "selection = random.randrange(len(train)-1)\n",
    "image, label = train[selection]\n",
    "\n",
    "# Plot the image\n",
    "print(f\"Default image shape: {image.shape}\")\n",
    "image = image.view([28,28])\n",
    "\n",
    "print(f\"Reshaped image shape: {image.shape}\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "print(f\"Total pixels: {image.shape[0] * image.shape[1]}\")\n",
    "\n",
    "# Print the label\n",
    "print(f\"The label for this image: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### 4. Artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # TODO: define layers\n",
    "  \n",
    "  def forward(self, x : torch.Tensor):\n",
    "\n",
    "    # TODO: define forward pass\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = ...  # TODO: define the learning rate\n",
    "NUM_EPOCHS = ... # TODO: define the number of epochs (i.e. passes over the dataset)\n",
    "criterion = nn.CrossEntropyLoss()  # The loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(DEVICE)   # Create an instance of the MLP model and move it to device (GPU or CPU)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR) # The optimizer (here, SGD - you can also try ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = fit(\n",
    "    model,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    device = DEVICE,\n",
    "    optimizer = optimizer,\n",
    "    criterion = criterion,\n",
    "    num_epochs = NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = train_loader,  # evaluate on training data\n",
    "    criterion = criterion,\n",
    "    device = DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = val_loader,  # evaluate on validation data\n",
    "    criterion = criterion,\n",
    "    device = DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = test_loader,  # evaluate on testing data\n",
    "    criterion = criterion,\n",
    "    device = DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
