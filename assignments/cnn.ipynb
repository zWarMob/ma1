{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "#### Part II: Convolutional Neural Networks\n",
    "\n",
    "***\n",
    "\n",
    "Please see the description of the assignment in the README file (section 2) <br>\n",
    "**Guide notebook**: [material/cnns_pytorch.ipynb](material/cnns_pytorch.ipynb)\n",
    "\n",
    "Table of contents:\n",
    "1. Activate GPU\n",
    "2. Load data\n",
    "3. Inspect data\n",
    "4. Convolutional neural network (**Where you will implement the CNN**)\n",
    "5. Training hyperparameters (**Where you will add training parameters**)\n",
    "6. Training\n",
    "7. Plot loss and accuracy\n",
    "8. Evaluate\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision  # noqa\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F  # noqa\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a bit of a hack in case your IDE wants to run the notebook from /`assignment/` and not the project root folder `/ma1`. We need the working directory to be `/ma1` for local imports to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/nicolai/Desktop/cbs/aiml25/ma1\n"
     ]
    }
   ],
   "source": [
    "# Ensure the working directory is set to the \"ma1\" folder.\n",
    "while Path.cwd().name != \"ma1\" and \"ma1\" in str(Path.cwd()):\n",
    "    os.chdir(\"..\")  # Move up one directory\n",
    "print(f\"Working directory set to: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are local files imported into this notebook. This is one of the advantages of not using an online notebook like Google Colab or stand-alone notebooks like Jupyter: We can import local files and use them in our code, thus making it easier to manage our code and create a more modular structure.\n",
    "\n",
    "In `/src`, we have the following files:\n",
    "- `utils.py`: Contains utility functions (e.g., setting our device to GPU if available)\n",
    "- `data.py`: Contains functions to load data, train/validation split, and data augmentation\n",
    "- `training.py`: Contains a single but very important function: Our training loop.\n",
    "- `evaluation.py`: Contains functions to evaluate our model and produce a classification report\n",
    "- `visualization.py`: Contains functions to visualize our data and model performance\n",
    "\n",
    "You are encouraged to look at these files to understand how they work. Particularly, the training and evaluation files are important to understand how we train our model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local files\n",
    "from src.utils import get_device\n",
    "from src.data import load_torch_data, to_dataloader, train_val_split\n",
    "from src.training import fit\n",
    "from src.evaluation import evaluate\n",
    "from src.visualize import plot_training_history, plot_probabilities, show_cifar_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Activate GPU\n",
    "If available. Note that this is not necessary, but it will speed up your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()  # will default to 'cpu' if gpu is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # number of samples per batch\n",
    "\n",
    "torch.manual_seed(42)  # Set a random seed to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable preprocessing_stepss for later use.\n",
    "# Think of this like sci-kit learn's pipeline method.\n",
    "preprocessing_steps = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32,32)),             # Cifar-10 images are 32x32\n",
    "        transforms.RandomCrop(32, padding=4),   # Data augmentation step: Randomly crop the image to 32x32\n",
    "        transforms.RandomHorizontalFlip(),      # Data augmentation step: Randomly flip image horizontally\n",
    "        transforms.ToTensor(),                  # Convert the image to a pytorch tensor\n",
    "        transforms.Normalize(                   # Normalize the image (i.e. scale the image to have a mean of 0 and a standard deviation of 1)\n",
    "            mean=[0.4914, 0.4822, 0.4465],      # FYI: The mean of the CIFAR10 dataset for your convenience\n",
    "            std=[0.2023, 0.1994, 0.2010]        # FYI the standard deviation of the CIFAR10 dataset\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load the training/validation data\n",
    "train_val = load_torch_data(\n",
    "    dataset=\"CIFAR10\",\n",
    "    root = 'data',                     # The root directory where the dataset will be stored\n",
    "    download = True,                   # If the dataset is not found at root, it will be downloaded\n",
    "    train = True,                      # The train dataset (as opposed to the test dataset)\n",
    "    transform = preprocessing_steps  # transformations to be applied to the dataset (see steps above)\n",
    ")\n",
    "\n",
    "# load the testing data\n",
    "test = load_torch_data(\n",
    "    dataset = \"CIFAR10\",\n",
    "    root = 'data',\n",
    "    download = True,\n",
    "    train = False,\n",
    "    transform = preprocessing_steps\n",
    ")\n",
    "\n",
    "f\"{len(train_val)=}, {len(test)=}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data in training and validation (just like train_test_split in sklearn)\n",
    "train, val = train_val_split(train_val, val_ratio=0.2, seed=42)\n",
    "\n",
    "f\"{len(val)=}, {len(train)=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloders for easy batch loading during training\n",
    "train_loader = to_dataloader(train, batch_size = batch_size, shuffle = True)\n",
    "val_loader = to_dataloader(val, batch_size = batch_size, shuffle = False)\n",
    "test_loader = to_dataloader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick a random example from the training set\n",
    "classes = train.dataset.classes\n",
    "selection = random.randrange(len(train)-1)\n",
    "image, label = train[selection]\n",
    "\n",
    "show_cifar_img(image, label, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        ######################\n",
    "        # Convolutional layers\n",
    "        # (pattern augmentation)\n",
    "        ######################\n",
    "\n",
    "        # Conv2D is a convolutional layer that applies a 2D convolution over an input signal.\n",
    "        # TODO: set the in_channels, out_channels, kernel_size, stride, and padding parameters\n",
    "        self.conv1 = nn.Conv2d(..., ..., kernel_size=..., stride=..., padding=...)\n",
    "\n",
    "        # TODO: add more layers such as BatchNorm2d, MaxPool2d, and Conv2d\n",
    "\n",
    "        ######################\n",
    "        # Fully connected layers\n",
    "        # (pattern recognition)\n",
    "        ######################\n",
    "\n",
    "        # \"Flatten\" converts a 2D matrix to a vector to be able to feed it to the fully\n",
    "        # connected layers for classification. Should be between the convolutional and linear\n",
    "        # layers (as the convolutional layers output 3D tensors, and the linear layers expect 1D vectors)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Linear is a fully connected layer that applies a linear transformation to the incoming data\n",
    "        # TODO: set the in_features and out_features parameters\n",
    "        self.fc1 = nn.Linear(..., ...)\n",
    "\n",
    "        # TODO: add more layers such as ReLU, Dropout, and Linear\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ######################\n",
    "        # Convolutional forward pass\n",
    "        ######################\n",
    "        \n",
    "        # TODO: use the layers defined in the __init__ method to build the forward pass\n",
    "\n",
    "        x = self.flatten(x) # flatten the tensor (convert 2D matrix to a vector)\n",
    "\n",
    "        ######################\n",
    "        # Fully connected forward pass\n",
    "        ######################\n",
    "\n",
    "        # TODO: use the layers defined in the __init__ method to build the forward pass\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "LEARNING_RATE = ... # TODO: Set the learning rate\n",
    "WEIGHT_DECAY = ... # TODO: Set the weight decay (i.e. L2 regularization)\n",
    "NUM_EPOCHS = ... # TODO: Set the number of epochs to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) # FYI; Sends the model to the GPU if set earlier\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = fit(\n",
    "    model = model,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    optimizer = optimizer,\n",
    "    criterion = criterion,\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    device = device,\n",
    "    flatten = False  # don't flatten input tensors to 1D before passing to model. Convolutonal layers expect nD.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on training data, validation data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = train_loader,  # evaluate on training data\n",
    "    device = device,\n",
    "    criterion = criterion,\n",
    "    flatten = False  # don't flatten input tensors to 1D. Convolutonal layers expect nD.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single image and its label from the test dataset\n",
    "index = np.random.randint(len(test))  # Randomly select an index\n",
    "image, label = test[index]\n",
    "\n",
    "# Prepare the image for prediction\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    input_image = image.unsqueeze(0).to(device)                     # Add batch dimension and move to device\n",
    "    outputs = model(input_image)                                    # Get model predictions\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=0)  # Apply softmax to get probabilities\n",
    "\n",
    "plot_probabilities(\n",
    "    image = image,\n",
    "    label = label,\n",
    "    probabilities = probabilities, \n",
    "    classes = test.classes,\n",
    "    n = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = val_loader,  # evaluate on validation data\n",
    "    device = device,\n",
    "    criterion = criterion,\n",
    "    flatten = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    model = model,\n",
    "    data_loader = test_loader,  # evaluate on testing data\n",
    "    device = device,\n",
    "    criterion = criterion,\n",
    "    flatten = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
